<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>I. RAG | Daci Blog</title>
    <meta name="description" content="Daci的博客">
    <meta name="generator" content="VitePress v1.6.3">
    <link rel="preload stylesheet" href="/assets/style.f-orAREn.css" as="style">
    <link rel="preload stylesheet" href="/vp-icons.css" as="style">
    
    <script type="module" src="/assets/app.DvBmvMPr.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/theme.Dr5Fq-8O.js">
    <link rel="modulepreload" href="/assets/chunks/framework.BjlC_BXf.js">
    <link rel="modulepreload" href="/assets/en_ai_rag_rag1.md.BgQfIkUI.lean.js">
    <link rel="icon" type="image/png" href="/favicon.png">
    <link rel="icon" type="image/svg+xml" href="/logo.svg">
    <meta name="theme-color" content="#3eaf7c">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-32e39dcf><!--[--><!--]--><!--[--><span tabindex="-1" data-v-b340c8f7></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-b340c8f7>Skip to content</a><!--]--><!----><header class="VPNav" data-v-32e39dcf data-v-298a4f5a><div class="VPNavBar" data-v-298a4f5a data-v-883acc06><div class="wrapper" data-v-883acc06><div class="container" data-v-883acc06><div class="title" data-v-883acc06><div class="VPNavBarTitle has-sidebar" data-v-883acc06 data-v-64c800ee><a class="title" href="/en/" data-v-64c800ee><!--[--><!--]--><!--[--><img class="VPImage logo" src="/logo.svg" alt data-v-2662aff2><!--]--><span data-v-64c800ee>Daci</span><!--[--><!--]--></a></div></div><div class="content" data-v-883acc06><div class="content-body" data-v-883acc06><!--[--><!--]--><div class="VPNavBarSearch search" data-v-883acc06><!----></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-883acc06 data-v-0d30a5d7><span id="main-nav-aria-label" class="visually-hidden" data-v-0d30a5d7> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/en/" tabindex="0" data-v-0d30a5d7 data-v-fa9a032b><!--[--><span data-v-fa9a032b>Home</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/en/ai/" tabindex="0" data-v-0d30a5d7 data-v-fa9a032b><!--[--><span data-v-fa9a032b>AI</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-0d30a5d7 data-v-f1032559><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-f1032559><span class="text" data-v-f1032559><!----><span data-v-f1032559>Tech</span><span class="vpi-chevron-down text-icon" data-v-f1032559></span></span></button><div class="menu" data-v-f1032559><div class="VPMenu" data-v-f1032559 data-v-2c3610af><div class="items" data-v-2c3610af><!--[--><!--[--><div class="VPMenuLink" data-v-2c3610af data-v-c8d6d8c5><a class="VPLink link" href="/en/tech/frontend/" data-v-c8d6d8c5><!--[--><span data-v-c8d6d8c5>Frontend</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-2c3610af data-v-c8d6d8c5><a class="VPLink link" href="/en/tech/backend/" data-v-c8d6d8c5><!--[--><span data-v-c8d6d8c5>Backend</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-0d30a5d7 data-v-f1032559><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-f1032559><span class="text" data-v-f1032559><!----><span data-v-f1032559>Personal project</span><span class="vpi-chevron-down text-icon" data-v-f1032559></span></span></button><div class="menu" data-v-f1032559><div class="VPMenu" data-v-f1032559 data-v-2c3610af><div class="items" data-v-2c3610af><!--[--><!--[--><div class="VPMenuLink" data-v-2c3610af data-v-c8d6d8c5><a class="VPLink link vp-external-link-icon" href="http://122.51.102.153:10012/cesium.html" target="_blank" rel="noreferrer" data-v-c8d6d8c5><!--[--><span data-v-c8d6d8c5>Cesium</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-2c3610af data-v-c8d6d8c5><a class="VPLink link vp-external-link-icon" href="http://122.51.102.153:10010/" target="_blank" rel="noreferrer" data-v-c8d6d8c5><!--[--><span data-v-c8d6d8c5>LandAI</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/en/tools/" tabindex="0" data-v-0d30a5d7 data-v-fa9a032b><!--[--><span data-v-fa9a032b>Tools</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-0d30a5d7 data-v-f1032559><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-f1032559><span class="text" data-v-f1032559><!----><span data-v-f1032559>About</span><span class="vpi-chevron-down text-icon" data-v-f1032559></span></span></button><div class="menu" data-v-f1032559><div class="VPMenu" data-v-f1032559 data-v-2c3610af><div class="items" data-v-2c3610af><!--[--><!--[--><div class="VPMenuLink" data-v-2c3610af data-v-c8d6d8c5><a class="VPLink link" href="/en/about/fitness/" data-v-c8d6d8c5><!--[--><span data-v-c8d6d8c5>Fitness</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-2c3610af data-v-c8d6d8c5><a class="VPLink link" href="/en/about/life/" data-v-c8d6d8c5><!--[--><span data-v-c8d6d8c5>Life</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--]--></nav><div class="VPFlyout VPNavBarTranslations translations" data-v-883acc06 data-v-aba76a3d data-v-f1032559><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="Change language" data-v-f1032559><span class="text" data-v-f1032559><span class="vpi-languages option-icon" data-v-f1032559></span><!----><span class="vpi-chevron-down text-icon" data-v-f1032559></span></span></button><div class="menu" data-v-f1032559><div class="VPMenu" data-v-f1032559 data-v-2c3610af><!----><!--[--><!--[--><div class="items" data-v-aba76a3d><p class="title" data-v-aba76a3d>English</p><!--[--><div class="VPMenuLink" data-v-aba76a3d data-v-c8d6d8c5><a class="VPLink link" href="/ai/rag/rag1.html" data-v-c8d6d8c5><!--[--><span data-v-c8d6d8c5>简体中文</span><!--]--></a></div><!--]--></div><!--]--><!--]--></div></div></div><div class="VPNavBarAppearance appearance" data-v-883acc06 data-v-be3201b0><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-be3201b0 data-v-23920a8f data-v-222e4e54><span class="check" data-v-222e4e54><span class="icon" data-v-222e4e54><!--[--><span class="vpi-sun sun" data-v-23920a8f></span><span class="vpi-moon moon" data-v-23920a8f></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-883acc06 data-v-ab7c40f2 data-v-5480e48c><!--[--><a class="VPSocialLink no-icon" href="https://github.com/zhangdanqing/zhangdanqing.github.io" aria-label="github" target="_blank" rel="noopener" data-v-5480e48c data-v-1dcf205f><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-883acc06 data-v-b0498f15 data-v-f1032559><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-f1032559><span class="vpi-more-horizontal icon" data-v-f1032559></span></button><div class="menu" data-v-f1032559><div class="VPMenu" data-v-f1032559 data-v-2c3610af><!----><!--[--><!--[--><div class="group translations" data-v-b0498f15><p class="trans-title" data-v-b0498f15>English</p><!--[--><div class="VPMenuLink" data-v-b0498f15 data-v-c8d6d8c5><a class="VPLink link" href="/ai/rag/rag1.html" data-v-c8d6d8c5><!--[--><span data-v-c8d6d8c5>简体中文</span><!--]--></a></div><!--]--></div><div class="group" data-v-b0498f15><div class="item appearance" data-v-b0498f15><p class="label" data-v-b0498f15>Appearance</p><div class="appearance-action" data-v-b0498f15><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-b0498f15 data-v-23920a8f data-v-222e4e54><span class="check" data-v-222e4e54><span class="icon" data-v-222e4e54><!--[--><span class="vpi-sun sun" data-v-23920a8f></span><span class="vpi-moon moon" data-v-23920a8f></span><!--]--></span></span></button></div></div></div><div class="group" data-v-b0498f15><div class="item social-links" data-v-b0498f15><div class="VPSocialLinks social-links-list" data-v-b0498f15 data-v-5480e48c><!--[--><a class="VPSocialLink no-icon" href="https://github.com/zhangdanqing/zhangdanqing.github.io" aria-label="github" target="_blank" rel="noopener" data-v-5480e48c data-v-1dcf205f><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-883acc06 data-v-41ff4f54><span class="container" data-v-41ff4f54><span class="top" data-v-41ff4f54></span><span class="middle" data-v-41ff4f54></span><span class="bottom" data-v-41ff4f54></span></span></button></div></div></div></div><div class="divider" data-v-883acc06><div class="divider-line" data-v-883acc06></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-32e39dcf data-v-14b7a3aa><div class="container" data-v-14b7a3aa><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-14b7a3aa><span class="vpi-align-left menu-icon" data-v-14b7a3aa></span><span class="menu-text" data-v-14b7a3aa>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-14b7a3aa data-v-cd011971><button data-v-cd011971>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-32e39dcf data-v-7f452ddf><div class="curtain" data-v-7f452ddf></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-7f452ddf><span class="visually-hidden" id="sidebar-aria-label" data-v-7f452ddf> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-a7d3a93e><section class="VPSidebarItem level-0" data-v-a7d3a93e data-v-48f9c2c2><div class="item" role="button" tabindex="0" data-v-48f9c2c2><div class="indicator" data-v-48f9c2c2></div><h2 class="text" data-v-48f9c2c2>AI</h2><!----></div><div class="items" data-v-48f9c2c2><!--[--><div class="VPSidebarItem level-1 is-link" data-v-48f9c2c2 data-v-48f9c2c2><div class="item" data-v-48f9c2c2><div class="indicator" data-v-48f9c2c2></div><a class="VPLink link link" href="/en/ai/" data-v-48f9c2c2><!--[--><p class="text" data-v-48f9c2c2>AI Tools Guide</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-48f9c2c2 data-v-48f9c2c2><div class="item" data-v-48f9c2c2><div class="indicator" data-v-48f9c2c2></div><a class="VPLink link link" href="/en/ai/cursor.html" data-v-48f9c2c2><!--[--><p class="text" data-v-48f9c2c2>AI Applications in Cursor</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-48f9c2c2 data-v-48f9c2c2><div class="item" data-v-48f9c2c2><div class="indicator" data-v-48f9c2c2></div><a class="VPLink link link" href="/en/ai/windsurf.html" data-v-48f9c2c2><!--[--><p class="text" data-v-48f9c2c2>Exploring AI in Windsurf Editor</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-48f9c2c2 data-v-48f9c2c2><div class="item" data-v-48f9c2c2><div class="indicator" data-v-48f9c2c2></div><a class="VPLink link link" href="/en/ai/rag/rag1.html" data-v-48f9c2c2><!--[--><p class="text" data-v-48f9c2c2>RAG Analysis</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-48f9c2c2 data-v-48f9c2c2><div class="item" data-v-48f9c2c2><div class="indicator" data-v-48f9c2c2></div><a class="VPLink link link" href="/en/ai/rag/rag2.html" data-v-48f9c2c2><!--[--><p class="text" data-v-48f9c2c2>Analysis of Large Model Application Framework: RAG, Agent, Fine tuning, Prompt Word Engineering</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-48f9c2c2 data-v-48f9c2c2><div class="item" data-v-48f9c2c2><div class="indicator" data-v-48f9c2c2></div><a class="VPLink link link" href="/en/ai/rag/rag3.html" data-v-48f9c2c2><!--[--><p class="text" data-v-48f9c2c2>Quickly build a RAG Q&A system that supports multimodal documents</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-48f9c2c2 data-v-48f9c2c2><div class="item" data-v-48f9c2c2><div class="indicator" data-v-48f9c2c2></div><a class="VPLink link link" href="/en/ai/rag/rag4.html" data-v-48f9c2c2><!--[--><p class="text" data-v-48f9c2c2>RAG text segmentation, from strategy to optimization</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-32e39dcf data-v-82c0ecc6><div class="VPDoc has-sidebar has-aside" data-v-82c0ecc6 data-v-06ef2308><!--[--><!--]--><div class="container" data-v-06ef2308><div class="aside" data-v-06ef2308><div class="aside-curtain" data-v-06ef2308></div><div class="aside-container" data-v-06ef2308><div class="aside-content" data-v-06ef2308><div class="VPDocAside" data-v-06ef2308 data-v-75b22be8><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-75b22be8 data-v-a2152973><div class="content" data-v-a2152973><div class="outline-marker" data-v-a2152973></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-a2152973>On this page</div><ul class="VPDocOutlineItem root" data-v-a2152973 data-v-80416021><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-75b22be8></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-06ef2308><div class="content-container" data-v-06ef2308><!--[--><!--]--><main class="main" data-v-06ef2308><div style="position:relative;" class="vp-doc _en_ai_rag_rag1" data-v-06ef2308><div><h1 id="i-rag" tabindex="-1"><strong>I. RAG</strong> <a class="header-anchor" href="#i-rag" aria-label="Permalink to &quot;**I. RAG**&quot;">​</a></h1><h2 id="_1-what-is-rag" tabindex="-1"><strong>1. What Is RAG</strong> <a class="header-anchor" href="#_1-what-is-rag" aria-label="Permalink to &quot;**1. What Is RAG**&quot;">​</a></h2><p>Retrieval-Augmented Generation (RAG) is an architecture that combines <strong>dynamic information retrieval</strong> with <strong>static knowledge generation</strong>. It works by extracting relevant fragments from structured knowledge bases in real time, providing contextual anchors for large language models (LLMs).</p><p>RAG supplements the data in a large language model with external knowledge sources of your choice, such as data repositories, collections of texts, and existing documents. This method first splits these resources into smaller chunks, indexes them in a vector database, and then uses them as references to deliver more accurate answers.</p><p>The practical value of RAG lies in its ability to direct the LLM to retrieve specific, real-time information from one or more factual sources you select. RAG can save costs by providing a customized experience without incurring the expenses of model training and fine-tuning. It also allows only the most relevant information to be sent when querying the LLM (rather than lengthy, redundant documents), thus conserving resources.</p><h2 id="_2-principles" tabindex="-1"><strong>2. Principles</strong> <a class="header-anchor" href="#_2-principles" aria-label="Permalink to &quot;**2. Principles**&quot;">​</a></h2><p>The RAG architecture operates by retrieving data from external sources, processing it into the context of the LLM, and then generating answers based on these combined sources. This process involves three main stages: data preparation, retrieval, and generation.</p><h3 id="step-1-data-preparation-for-retrieval" tabindex="-1"><strong>Step 1: Data Preparation (For Retrieval)</strong> <a class="header-anchor" href="#step-1-data-preparation-for-retrieval" aria-label="Permalink to &quot;**Step 1: Data Preparation (For Retrieval)**&quot;">​</a></h3><ul><li><p><strong>Source Document Acquisition and Loading:</strong> Identify and acquire the source documents to be shared with the LLM, ensuring they are in a format the model can interpret—typically text files, database tables, or PDFs. Regardless of the original format, each document must be converted into a text file before embedding in the vector database. This is also known as the ETL phase: Extract, Transform, and Load. ETL ensures raw data is cleaned and organized, making it ready for storage, analysis, and machine learning.</p></li><li><p><strong>Transformation:</strong> Perform &quot;text splitting&quot; or &quot;chunking&quot; to prepare documents for retrieval. This means parsing the updated documents and organizing them into relevant &quot;chunks&quot; according to various features. For example, a document organized by paragraphs may be easier for the model to search and retrieve than one arranged by tables and charts.</p><p>Chunking can be based on semantics, sentences, tokens, formatting, HTML characters, or code types. Many open-source frameworks facilitate document injection, including <a href="https://www.llamaindex.ai/open-source" target="_blank" rel="noreferrer">LlamaIndex</a> and <a href="https://www.langchain.com/" target="_blank" rel="noreferrer">LangChain</a>.</p></li><li><p><strong>Embedding:</strong> Embedding uses specialized machine learning models (vector embedding models) to convert data into numerical vectors, enabling mathematical operations to assess similarity and difference between data. Embeddings allow text (or images) to be converted into vectors that capture the core meaning of the content while discarding irrelevant details. The embedding process assigns a numerical value (e.g., [1.2, -0.9, 0.3]) to each data chunk and indexes it within a larger system such as a vector database.</p><p>In the vector database, these values help the RAG architecture indicate associations between content blocks and organize the data to optimize retrieval. This indexing approach is designed to structure vectors such that similar concepts are stored near each other in the coordinate space. For example, &quot;coffee&quot; and &quot;tea&quot; will be close together, as will &quot;hot beverage.&quot; Unrelated concepts like &quot;mobile phone&quot; and &quot;television&quot; will be farther away. The distance or proximity between two vector points helps the model decide which information to retrieve and include in the output for a user query.</p></li><li><p><strong>Storage:</strong> Combined data from multiple sources (your chosen external documents and the LLM) are stored in a central repository.</p></li></ul><h3 id="step-2-retrieval" tabindex="-1"><strong>Step 2: Retrieval</strong> <a class="header-anchor" href="#step-2-retrieval" aria-label="Permalink to &quot;**Step 2: Retrieval**&quot;">​</a></h3><ul><li><p>Once data is indexed in the vector database, algorithms search and retrieve information fragments relevant to user prompts and queries. Frameworks like LangChain support many retrieval algorithms, including those based on semantic similarity, metadata, or parent documents.</p><p>In open-domain user settings, information retrieval comes from indexed documents on the internet, accessed through APIs from these information sources. In closed-domain enterprise settings, information needs to remain confidential and unaffected by external sources; RAG enables local retrieval and enhanced security.</p><p>Finally, the retrieved data is injected into the prompt and sent to the LLM for processing.</p></li></ul><h3 id="step-3-generation" tabindex="-1"><strong>Step 3: Generation</strong> <a class="header-anchor" href="#step-3-generation" aria-label="Permalink to &quot;**Step 3: Generation**&quot;">​</a></h3><ul><li><strong>Output:</strong> The response is delivered to the user. If RAG works as intended, the user receives an accurate answer based on the provided source knowledge.</li></ul><h2 id="_3-how-to-implement" tabindex="-1"><strong>3. How to Implement</strong> <a class="header-anchor" href="#_3-how-to-implement" aria-label="Permalink to &quot;**3. How to Implement**&quot;">​</a></h2><ol><li><p><strong>Knowledge Base Construction Phase</strong></p><ul><li>Data Source Assessment: Coverage, quality, and update frequency</li><li>Metadata Design: Source, timeliness, and authority tags</li><li>Version Management: Incremental updates and rollback mechanisms</li></ul></li><li><p><strong>System Integration Phase</strong></p><ul><li>Retrieval Strategy Configuration: <ul><li>Single-pass retrieval vs. multi-turn refinement</li><li>Exact matching vs. semantic generalization</li></ul></li><li>Generation Parameter Tuning: <ul><li>Citation formatting normalization</li><li>Terminology consistency maintenance</li></ul></li></ul></li><li><p><strong>Continuous Optimization Phase</strong></p><ul><li>Quality Monitoring Metrics: <ul><li>Retrieval hit rate</li><li>Factual accuracy of generation</li><li>User satisfaction</li></ul></li><li>Feedback Loop Design: <ul><li>Error case annotation</li><li>Automatic retraining triggers</li></ul></li></ul></li></ol><h2 id="_4-advantages" tabindex="-1"><strong>4. Advantages</strong> <a class="header-anchor" href="#_4-advantages" aria-label="Permalink to &quot;**4. Advantages**&quot;">​</a></h2><p>Because RAG has a built-in retrieval mechanism, it can leverage additional data sources beyond the conventional training set of the LLM. By grounding the LLM in a series of external, verifiable facts, RAG achieves several beneficial goals:</p><p><strong>Accuracy</strong><br> RAG provides the LLM with reference sources, enabling user verification. You can also design a RAG system to respond with &quot;I don&#39;t know&quot; when queries fall outside its knowledge scope. Overall, RAG can reduce the likelihood of the LLM sharing incorrect or misleading information, which in turn may increase user trust.</p><p><strong>Cost-Effectiveness</strong><br> Retraining and fine-tuning large language models is expensive and time-consuming, similar to building a <a href="https://www.redhat.com/en/topics/ai/what-are-foundation-models" target="_blank" rel="noreferrer">foundation model</a> from scratch and adding domain-specific information. With RAG, users can introduce new data into the LLM simply by uploading documents or files, making it easy to replace or update information sources.</p><p>RAG also reduces inference costs. LLM queries are costly—if you run the model locally, your own hardware must meet demanding requirements; if you use external APIs, you incur billing costs. RAG enables you to send only the most relevant portions of reference materials, rather than entire documents, reducing query size and improving efficiency.</p><p><strong>Developer Control</strong><br> Compared to traditional fine-tuning, RAG offers a more convenient and direct way to obtain feedback, troubleshoot, and fix applications. For developers, the major advantage of RAG is the ability to leverage up-to-date information streams from specific domains.</p><p><strong>Data Sovereignty and Privacy</strong><br> Using sensitive information to fine-tune LLMs has previously been risky, as LLMs might leak information from their training data. RAG allows sensitive data to remain local while still being used to inform local or trusted external LLMs, providing a solution for privacy concerns. RAG architectures can also restrict sensitive information retrieval to different authorization levels, so certain users can access information based on their security permissions.</p><h2 id="_5-application-scenarios" tabindex="-1"><strong>5. Application Scenarios</strong> <a class="header-anchor" href="#_5-application-scenarios" aria-label="Permalink to &quot;**5. Application Scenarios**&quot;">​</a></h2><table tabindex="0"><thead><tr><th style="text-align:center;">Scenario Type</th><th style="text-align:center;">Core Requirement</th><th style="text-align:center;">Key Technical Adaptation</th></tr></thead><tbody><tr><td style="text-align:center;">Enterprise Knowledge Base</td><td style="text-align:center;">Multi-source integration</td><td style="text-align:center;">Hierarchical access control</td></tr><tr><td style="text-align:center;">Intelligent Customer Service</td><td style="text-align:center;">Real-time accuracy</td><td style="text-align:center;">Dialogue state management</td></tr><tr><td style="text-align:center;">Academic Research</td><td style="text-align:center;">Source traceability</td><td style="text-align:center;">Professional terminology handling</td></tr><tr><td style="text-align:center;">Compliance Review</td><td style="text-align:center;">Clause matching accuracy</td><td style="text-align:center;">Legal validity assessment</td></tr></tbody></table><p>RAG architectures have many potential use cases. The most popular include:</p><ul><li><strong>Customer Service:</strong> Programming chatbots to answer customer inquiries using in-depth knowledge of specific documents, thus shortening resolution times and making customer support systems more efficient.</li><li><strong>Generating Insights:</strong> RAG can help query existing documents. By connecting LLMs to annual reports, marketing documents, social media comments, customer reviews, survey results, research documents, or other materials using RAG, you can find answers that help you better understand your resources. Note that RAG can connect directly to real-time data sources (such as social media feeds, websites, or other frequently updated resources) to generate up-to-date and practical answers.</li><li><strong>Medical Information Systems:</strong> RAG can improve systems that provide medical information or advice. It can review factors like personal medical history, appointment scheduling, and the latest research and guidelines, helping patients receive the support and services they need.</li></ul><h2 id="_6-solution-steps" tabindex="-1"><strong>6. Solution Steps</strong> <a class="header-anchor" href="#_6-solution-steps" aria-label="Permalink to &quot;**6. Solution Steps**&quot;">​</a></h2><ol><li>Create a RAG application</li><li>Build a document processing pipeline</li><li>Browse the large language model catalog</li><li>Select an appropriate model</li></ol><h2 id="_7-concept-clarification" tabindex="-1"><strong>7. Concept Clarification</strong> <a class="header-anchor" href="#_7-concept-clarification" aria-label="Permalink to &quot;**7. Concept Clarification**&quot;">​</a></h2><h3 id="_1-vector-database" tabindex="-1">1. Vector Database <a class="header-anchor" href="#_1-vector-database" aria-label="Permalink to &quot;1. Vector Database&quot;">​</a></h3><p>A vector database is a specialized database system for storing, retrieving, and managing vector embeddings. It plays a central role in applications that combine with large language models.</p><p>Traditional databases are not effective at handling high-dimensional vector similarity searches. Vector databases (such as Milvus, Pinecone, Weaviate) are optimized for these operations and support large-scale data.</p></div></div></main><footer class="VPDocFooter" data-v-06ef2308 data-v-c461bbcf><!--[--><!--]--><!----><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-c461bbcf><span class="visually-hidden" id="doc-footer-aria-label" data-v-c461bbcf>Pager</span><div class="pager" data-v-c461bbcf><!----></div><div class="pager" data-v-c461bbcf><a class="VPLink link pager-link next" href="/en/ai/" data-v-c461bbcf><!--[--><span class="desc" data-v-c461bbcf>Next page</span><span class="title" data-v-c461bbcf>AI Tools Guide</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-32e39dcf data-v-5458bf99><div class="container" data-v-5458bf99><p class="message" data-v-5458bf99>用心记录，温暖分享</p><p class="copyright" data-v-5458bf99> 2024 Daci Blog</p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"about_fitness_index.md\":\"Bou26D0Q\",\"about_fitness_training_warmup1.md\":\"DaJAcpIR\",\"about_fitness_training_warmup2.md\":\"CW0x0uvD\",\"about_life_index.md\":\"CXbzT0g_\",\"about_life_thoughts_growth-mindset.md\":\"DothoJZu\",\"ai_cursor.md\":\"DoIxipQl\",\"ai_index.md\":\"BXdtWxVV\",\"ai_rag_rag1.md\":\"DcqMX1H9\",\"ai_rag_rag2.md\":\"u6NiAyZc\",\"ai_rag_rag3.md\":\"CQNjp5Y9\",\"ai_rag_rag4.md\":\"D9UiMew5\",\"ai_windsurf.md\":\"rI8GWiq6\",\"en_about_fitness_index.md\":\"CR4hSf6R\",\"en_about_fitness_training_warmup1.md\":\"CL_G46HX\",\"en_about_fitness_training_warmup2.md\":\"BH_bcG88\",\"en_about_life_index.md\":\"chI4W3Wr\",\"en_about_life_thoughts_growth-mindset.md\":\"ByVm340J\",\"en_ai_cursor.md\":\"BKBwgDf3\",\"en_ai_index.md\":\"C_fO7ew3\",\"en_ai_rag_rag1.md\":\"BgQfIkUI\",\"en_ai_rag_rag2.md\":\"BKIpR57u\",\"en_ai_rag_rag3.md\":\"WiNxM9uH\",\"en_ai_rag_rag4.md\":\"OUTPwYaE\",\"en_ai_windsurf.md\":\"C_QNWWj4\",\"en_index.md\":\"CMKipQKC\",\"en_markdown-examples.md\":\"Bur12mIb\",\"en_tech_backend_index.md\":\"ltmUyQ_J\",\"en_tech_frontend_20250307.md\":\"DlVZMUfG\",\"en_tech_frontend_index.md\":\"DIJIjZrz\",\"en_tech_ops_docker_basic-usage.md\":\"yV3omPMd\",\"en_tech_ops_index.md\":\"CXfV4Buh\",\"en_tools_index.md\":\"BizG2mWx\",\"index.md\":\"BZUE4Mp3\",\"tech_backend_index.md\":\"BzUtPg_W\",\"tech_frontend_20250307.md\":\"ZBu71huP\",\"tech_frontend_index.md\":\"C4U-7EDh\",\"tech_frontend_javascript-basics.md\":\"CQqAw1sd\",\"tech_ops_docker_basic-usage.md\":\"DkYSGKfn\",\"tech_ops_index.md\":\"Ca3w2Wmr\",\"tools_index.md\":\"Cx0LaOrB\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"Daci Blog\",\"description\":\"Daci的博客\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"siteTitle\":\"Daci\",\"logo\":\"/logo.svg\",\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/zhangdanqing/zhangdanqing.github.io\"}],\"footer\":{\"message\":\"用心记录，温暖分享\",\"copyright\":\" 2024 Daci Blog\"}},\"locales\":{\"root\":{\"label\":\"简体中文\",\"lang\":\"zh-CN\",\"themeConfig\":{\"nav\":[{\"text\":\"首页\",\"link\":\"/\"},{\"text\":\"AI\",\"link\":\"/ai/\"},{\"text\":\"技术\",\"items\":[{\"text\":\"前端\",\"link\":\"/tech/frontend/\"},{\"text\":\"后端\",\"link\":\"/tech/backend/\"}]},{\"text\":\"个人项目\",\"items\":[{\"text\":\"Cesium\",\"link\":\"http://122.51.102.153:10012/cesium.html\"},{\"text\":\"LandAI\",\"link\":\"http://122.51.102.153:10010/\"}]},{\"text\":\"工具\",\"link\":\"/tools/\"},{\"text\":\"关于\",\"items\":[{\"text\":\"健身\",\"link\":\"/about/fitness/\"},{\"text\":\"生活\",\"link\":\"/about/life/\"}]}],\"sidebar\":{\"/ai/\":[{\"text\":\"AI\",\"items\":[{\"text\":\"AI 导览\",\"link\":\"/ai/\"},{\"text\":\"Cursor中AI的应用\",\"link\":\"/ai/cursor\"},{\"text\":\"深度探索Windsurf编辑器中AI的应用\",\"link\":\"/ai/windsurf\"},{\"text\":\"解析RAG\",\"link\":\"/ai/rag/rag1\"},{\"text\":\"大模型应用框架解析：RAG、Agent、微调、提示词工程\",\"link\":\"/ai/rag/rag2\"},{\"text\":\"快速搭建支持多模态文档的 RAG 问答系统\",\"link\":\"/ai/rag/rag3\"},{\"text\":\"RAG 文本分块，从策略到优化\",\"link\":\"/ai/rag/rag4\"}]}],\"/tools/\":[{\"text\":\"工具\",\"items\":[{\"text\":\"工具导览\",\"link\":\"/tools/\"}]}],\"/tech/frontend/\":[{\"text\":\"前端开发\",\"collapsed\":false,\"items\":[{\"text\":\"Next.js全栈实战：手把手集成NextAuth实现Google/GitHub一键登录\",\"link\":\"/tech/frontend/20250307\"},{\"text\":\"NocoBase 用户指南\",\"link\":\"/tech/frontend/\"}]}],\"/tech/backend/\":[{\"text\":\"后端开发\",\"collapsed\":true,\"items\":[{\"text\":\"使用 NestJS 搭建后端项目\",\"link\":\"/tech/backend/\"}]}],\"/about/fitness/\":[{\"text\":\"健身\",\"items\":[{\"text\":\"背部训练-上背和肩后束\",\"link\":\"/about/fitness/training/warmUp2\"},{\"text\":\"上肢热身/纠正性训练\",\"link\":\"/about/fitness/training/warmUp1\"},{\"text\":\"肩袖肌群受伤、肩关节弹响\",\"link\":\"/about/fitness/\"}]}],\"/about/life/\":[{\"text\":\"生活\",\"items\":[{\"text\":\"关于生活与成长的思考\",\"link\":\"/about/life/\"}]}]}}},\"en\":{\"label\":\"English\",\"lang\":\"en-US\",\"themeConfig\":{\"nav\":[{\"text\":\"Home\",\"link\":\"/en/\"},{\"text\":\"AI\",\"link\":\"/en/ai/\"},{\"text\":\"Tech\",\"items\":[{\"text\":\"Frontend\",\"link\":\"/en/tech/frontend/\"},{\"text\":\"Backend\",\"link\":\"/en/tech/backend/\"}]},{\"text\":\"Personal project\",\"items\":[{\"text\":\"Cesium\",\"link\":\"http://122.51.102.153:10012/cesium.html\"},{\"text\":\"LandAI\",\"link\":\"http://122.51.102.153:10010/\"}]},{\"text\":\"Tools\",\"link\":\"/en/tools/\"},{\"text\":\"About\",\"items\":[{\"text\":\"Fitness\",\"link\":\"/en/about/fitness/\"},{\"text\":\"Life\",\"link\":\"/en/about/life/\"}]}],\"sidebar\":{\"/en/ai/\":[{\"text\":\"AI\",\"items\":[{\"text\":\"AI Tools Guide\",\"link\":\"/en/ai/\"},{\"text\":\"AI Applications in Cursor\",\"link\":\"/en/ai/cursor\"},{\"text\":\"Exploring AI in Windsurf Editor\",\"link\":\"/en/ai/windsurf\"},{\"text\":\"RAG Analysis\",\"link\":\"en/ai/rag/rag1\"},{\"text\":\"Analysis of Large Model Application Framework: RAG, Agent, Fine tuning, Prompt Word Engineering\",\"link\":\"en/ai/rag/rag2\"},{\"text\":\"Quickly build a RAG Q&A system that supports multimodal documents\",\"link\":\"en/ai/rag/rag3\"},{\"text\":\"RAG text segmentation, from strategy to optimization\",\"link\":\"en/ai/rag/rag4\"}]}],\"/en/tools/\":[{\"text\":\"Tools\",\"items\":[{\"text\":\"Tools Guide\",\"link\":\"/en/tools/\"}]}],\"/en/tech/frontend/\":[{\"text\":\"Frontend Development\",\"collapsed\":false,\"items\":[{\"text\":\"Next.js Full-Stack Practice: Step-by-Step Integration of NextAuth for Google/GitHub One-Click Login\",\"link\":\"/en/tech/frontend/20250307\"},{\"text\":\"NocoBase User Guide\",\"link\":\"/en/tech/frontend/\"}]}],\"/en/tech/backend/\":[{\"text\":\"Backend Development\",\"collapsed\":true,\"items\":[{\"text\":\"Building a Backend Project with NestJS\",\"link\":\"/en/tech/backend/\"}]}],\"/en/about/fitness/\":[{\"text\":\"Fitness\",\"items\":[{\"text\":\"Back Training - Upper Back and Rear Deltoid\",\"link\":\"/en/about/fitness/training/warmUp2\"},{\"text\":\"Upper limb warm-up/corrective training\",\"link\":\"/en/about/fitness/training/warmUp1\"},{\"text\":\"Shoulder muscle group injury, shoulder joint popping\",\"link\":\"/en/about/fitness/\"}]}],\"/en/about/life/\":[{\"text\":\"Life\",\"items\":[{\"text\":\"Thoughts on Personal Work and Life\",\"link\":\"/en/about/life/\"}]}]}}}},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>