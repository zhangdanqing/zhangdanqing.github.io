import{_ as s,c as a,o as t,ae as e}from"./chunks/framework.BjlC_BXf.js";const k=JSON.parse('{"title":"The following are the most popular RAG Application Development Platforms recommendations. Depending on your technical needs and scenario, you can choose the most suitable tool:","description":"","frontmatter":{},"headers":[],"relativePath":"en/ai/rag/rag3.md","filePath":"en/ai/rag/rag3.md"}'),n={name:"en/ai/rag/rag3.md"};function l(r,i,o,p,h,d){return t(),a("div",null,i[0]||(i[0]=[e(`<h2 id="multiple-open-source-tools-and-platforms-are-available-for-quickly-building-multi-modal-rag-q-a-systems-without-developing-from-scratch" tabindex="-1">Multiple Open-Source Tools and Platforms Are Available for Quickly Building Multi-Modal RAG Q&amp;A Systems Without Developing from Scratch <a class="header-anchor" href="#multiple-open-source-tools-and-platforms-are-available-for-quickly-building-multi-modal-rag-q-a-systems-without-developing-from-scratch" aria-label="Permalink to &quot;Multiple Open-Source Tools and Platforms Are Available for Quickly Building Multi-Modal RAG Q&amp;A Systems Without Developing from Scratch&quot;">​</a></h2><h3 id="_1-using-existing-frameworks-for-developers" tabindex="-1"><strong>1. Using Existing Frameworks (For Developers)</strong> <a class="header-anchor" href="#_1-using-existing-frameworks-for-developers" aria-label="Permalink to &quot;**1. Using Existing Frameworks (For Developers)**&quot;">​</a></h3><h4 id="_1-langchain-llamaindex-openai" tabindex="-1"><strong>(1) LangChain + LlamaIndex + OpenAI</strong> <a class="header-anchor" href="#_1-langchain-llamaindex-openai" aria-label="Permalink to &quot;**(1) LangChain + LlamaIndex + OpenAI**&quot;">​</a></h4><ul><li><p><strong>Features</strong>: Highly flexible code, supports customizable workflows, suitable for complex scenarios.</p></li><li><p><strong>Sample Code</strong>:</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain.document_loaders </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> DirectoryLoader</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> llama_index </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> VectorStoreIndex, ServiceContext</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Load multi-format documents (automatic detection for PDF/Excel/images, etc.)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">loader </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> DirectoryLoader(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;./docs&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">glob</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;**/*&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">documents </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> loader.load()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Build vector index (auto chunking + embedding)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">index </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> VectorStoreIndex.from_documents(documents)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Q&amp;A query</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">query_engine </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> index.as_query_engine()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">response </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> query_engine.query(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;What is the product price in the image?&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(response.response)</span></span></code></pre></div></li></ul><h4 id="_2-hugging-face-transformers-pipeline" tabindex="-1"><strong>(2) Hugging Face Transformers Pipeline</strong> <a class="header-anchor" href="#_2-hugging-face-transformers-pipeline" aria-label="Permalink to &quot;**(2) Hugging Face Transformers Pipeline**&quot;">​</a></h4><ul><li><p><strong>Features</strong>: Free and open-source, supports local deployment.</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> transformers </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pipeline</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> PIL</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Image</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Multimodal Q&amp;A (text + image)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">vqa_pipeline </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pipeline(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;visual-question-answering&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">answer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> vqa_pipeline(Image.open(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;product.jpg&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;What is the product in the image?&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(answer)</span></span></code></pre></div></li></ul><hr><h3 id="_2-one-stop-tools-low-code-no-code" tabindex="-1"><strong>2. One-Stop Tools (Low-Code/No-Code)</strong> <a class="header-anchor" href="#_2-one-stop-tools-low-code-no-code" aria-label="Permalink to &quot;**2. One-Stop Tools (Low-Code/No-Code)**&quot;">​</a></h3><h4 id="_1-privategpt" tabindex="-1"><strong>(1) PrivateGPT</strong> <a class="header-anchor" href="#_1-privategpt" aria-label="Permalink to &quot;**(1) PrivateGPT**&quot;">​</a></h4><ul><li><p><strong>GitHub</strong>: <a href="https://github.com/imartinez/privateGPT" target="_blank" rel="noreferrer">https://github.com/imartinez/privateGPT</a></p></li><li><p><strong>Features</strong>:</p><ul><li>Supports PDF, Word, Excel, PPT, images (with OCR)</li><li>Runs locally, ensuring data privacy</li><li>Command-line interaction or API</li></ul></li><li><p><strong>Usage Steps</strong>:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span># Installation</span></span>
<span class="line"><span>git clone https://github.com/imartinez/privateGPT</span></span>
<span class="line"><span>cd privateGPT &amp;&amp; pip install -r requirements.txt</span></span>
<span class="line"><span></span></span>
<span class="line"><span># Place documents in the source_documents directory, then run</span></span>
<span class="line"><span>python ingest.py  # Build index</span></span>
<span class="line"><span>python privateGPT.py  # Start Q&amp;A</span></span></code></pre></div></li></ul><h4 id="_2-flowise" tabindex="-1"><strong>(2) Flowise</strong> <a class="header-anchor" href="#_2-flowise" aria-label="Permalink to &quot;**(2) Flowise**&quot;">​</a></h4><ul><li><strong>Official Site</strong>: <a href="https://flowiseai.com/" target="_blank" rel="noreferrer">https://flowiseai.com</a></li><li><strong>Features</strong>: <ul><li>Visual drag-and-drop RAG workflow builder</li><li>Supports PDF/Excel/text, extensible for image processing</li></ul></li><li><strong>Usage</strong>: <ol><li>Upload documents via the UI</li><li>Connect to a vector database (e.g., Pinecone)</li><li>Configure the LLM (e.g., GPT-4) to generate answers</li></ol></li></ul><hr><h3 id="_3-cloud-service-platforms-rapid-deployment-paid" tabindex="-1"><strong>3. Cloud Service Platforms (Rapid Deployment, Paid)</strong> <a class="header-anchor" href="#_3-cloud-service-platforms-rapid-deployment-paid" aria-label="Permalink to &quot;**3. Cloud Service Platforms (Rapid Deployment, Paid)**&quot;">​</a></h3><h4 id="_1-google-vertex-ai" tabindex="-1"><strong>(1) Google Vertex AI</strong> <a class="header-anchor" href="#_1-google-vertex-ai" aria-label="Permalink to &quot;**(1) Google Vertex AI**&quot;">​</a></h4><ul><li><strong>Features</strong>: <ul><li>Built-in document parsing (PDF/Excel/CSV)</li><li>Automatic Q&amp;A system generation</li></ul></li><li><strong>Steps</strong>: <ol><li>Upload documents via Google Cloud Console</li><li>Create a knowledge base using <code>Vertex AI Search</code></li><li>Query answers via API</li></ol></li></ul><h4 id="_2-azure-ai-document-intelligence" tabindex="-1"><strong>(2) Azure AI Document Intelligence</strong> <a class="header-anchor" href="#_2-azure-ai-document-intelligence" aria-label="Permalink to &quot;**(2) Azure AI Document Intelligence**&quot;">​</a></h4><ul><li><strong>Features</strong>: <ul><li>Supports OCR for scanned PDFs, images, tables</li><li>Integrates with Azure OpenAI for RAG</li></ul></li><li><strong>Documentation</strong>: <a href="https://learn.microsoft.com/azure/ai-services/document-intelligence/tutorial-rag" target="_blank" rel="noreferrer">Azure Multimodal RAG Tutorial</a></li></ul><hr><h3 id="_4-fast-integration-with-open-source-projects" tabindex="-1"><strong>4. Fast Integration with Open-Source Projects</strong> <a class="header-anchor" href="#_4-fast-integration-with-open-source-projects" aria-label="Permalink to &quot;**4. Fast Integration with Open-Source Projects**&quot;">​</a></h3><h4 id="_1-milvus-towhee" tabindex="-1"><strong>(1) Milvus + Towhee</strong> <a class="header-anchor" href="#_1-milvus-towhee" aria-label="Permalink to &quot;**(1) Milvus + Towhee**&quot;">​</a></h4><ul><li><p><strong>Scenario</strong>: Handling massive multi-modal data</p></li><li><p><strong>Sample Code</strong>:</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> towhee </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pipe, ops</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> milvus </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> default_server</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Start Milvus vector database</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">default_server.start()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Build multimodal processing pipeline</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">p </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    pipe.input(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;file_path&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    .map(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;file_path&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;text&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, ops.text_extractor())</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    .map(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;text&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;vec&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, ops.text_embedding.sbert())</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    .output(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;text&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;vec&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Query</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">results </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> p(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;report.pdf&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).get()</span></span></code></pre></div></li></ul><h4 id="_2-unstructured-io" tabindex="-1"><strong>(2) Unstructured.io</strong> <a class="header-anchor" href="#_2-unstructured-io" aria-label="Permalink to &quot;**(2) Unstructured.io**&quot;">​</a></h4><ul><li><p><strong>Document parsing tool</strong>: Unified processing for PDF/Excel/images, etc.</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> unstructured.partition.auto </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> partition</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">elements </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> partition(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;document.jpg&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">text </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\\n</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.join([e.text </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> e </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> elements])</span></span></code></pre></div></li></ul><hr><h3 id="selection-recommendations" tabindex="-1"><strong>Selection Recommendations</strong> <a class="header-anchor" href="#selection-recommendations" aria-label="Permalink to &quot;**Selection Recommendations**&quot;">​</a></h3><table tabindex="0"><thead><tr><th style="text-align:left;">Usage Scenario</th><th style="text-align:left;">Recommended Tool</th><th style="text-align:left;">Advantages</th><th style="text-align:left;">Disadvantages</th></tr></thead><tbody><tr><td style="text-align:left;">Fast Local Setup</td><td style="text-align:left;">PrivateGPT</td><td style="text-align:left;">One-click run, privacy</td><td style="text-align:left;">Weak image support</td></tr><tr><td style="text-align:left;">Enterprise Cloud</td><td style="text-align:left;">Google Vertex AI</td><td style="text-align:left;">Fully managed, large data</td><td style="text-align:left;">Higher cost</td></tr><tr><td style="text-align:left;">Visual Workflow</td><td style="text-align:left;">Flowise</td><td style="text-align:left;">No code, flexible expand</td><td style="text-align:left;">Need to configure multimodal</td></tr><tr><td style="text-align:left;">Open-Source</td><td style="text-align:left;">LangChain + LlamaIndex</td><td style="text-align:left;">Fully customizable</td><td style="text-align:left;">Higher development cost</td></tr></tbody></table><hr><h3 id="key-tips" tabindex="-1"><strong>Key Tips</strong> <a class="header-anchor" href="#key-tips" aria-label="Permalink to &quot;**Key Tips**&quot;">​</a></h3><ol><li><strong>Image Processing</strong>: If semantic understanding of images (not just OCR) is needed, use multimodal models such as: <ul><li>CLIP (open-source): generates image vectors</li><li>GPT-4 Vision (API): directly understands image content</li></ul></li><li><strong>Document Security</strong>: For sensitive data, consider PrivateGPT or locally deployed Milvus</li><li><strong>Cost Control</strong>: Cloud services are billed per usage; estimate usage before selecting a plan</li></ol><h1 id="the-following-are-the-most-popular-rag-application-development-platforms-recommendations-depending-on-your-technical-needs-and-scenario-you-can-choose-the-most-suitable-tool" tabindex="-1">The following are the most popular <strong>RAG Application Development Platforms</strong> recommendations. Depending on your technical needs and scenario, you can choose the most suitable tool: <a class="header-anchor" href="#the-following-are-the-most-popular-rag-application-development-platforms-recommendations-depending-on-your-technical-needs-and-scenario-you-can-choose-the-most-suitable-tool" aria-label="Permalink to &quot;The following are the most popular **RAG Application Development Platforms** recommendations. Depending on your technical needs and scenario, you can choose the most suitable tool:&quot;">​</a></h1><hr><h3 id="_1-langchain-llamaindex-code-first-highly-flexible" tabindex="-1"><strong>1. LangChain + LlamaIndex (Code-First, Highly Flexible)</strong> <a class="header-anchor" href="#_1-langchain-llamaindex-code-first-highly-flexible" aria-label="Permalink to &quot;**1. LangChain + LlamaIndex (Code-First, Highly Flexible)**&quot;">​</a></h3><ul><li><p><strong>Best for</strong>: Highly customized RAG workflows (complex retrieval strategies, multiple data sources)</p></li><li><p><strong>Core Capabilities</strong>:</p><ul><li><strong>LangChain</strong>: Provides RAG process orchestration (retrieval + generation chaining)</li><li><strong>LlamaIndex</strong>: Focused on document indexing and efficient retrieval optimization</li></ul></li><li><p><strong>Advantages</strong>:</p><ul><li>Supports Python/JS development, seamless integration with mainstream vector databases (Milvus, Pinecone, Weaviate)</li><li>Freely switch LLMs (OpenAI, Anthropic, local models, etc.)</li></ul></li><li><p><strong>Sample Code</strong>:</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> llama_index </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> VectorStoreIndex, SimpleDirectoryReader</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain.chat_models </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ChatOpenAI</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">documents </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> SimpleDirectoryReader(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;data&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).load_data()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">index </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> VectorStoreIndex.from_documents(documents)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">query_engine </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> index.as_query_engine(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">llm</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">ChatOpenAI())</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(query_engine.query(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;What are the core steps of RAG?&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span></code></pre></div></li><li><p><strong>Official Sites</strong>:</p><ul><li>LangChain</li><li>LlamaIndex</li></ul></li></ul><hr><h3 id="_2-haystack-enterprise-grade-rag-solution" tabindex="-1"><strong>2. Haystack (Enterprise-Grade RAG Solution)</strong> <a class="header-anchor" href="#_2-haystack-enterprise-grade-rag-solution" aria-label="Permalink to &quot;**2. Haystack (Enterprise-Grade RAG Solution)**&quot;">​</a></h3><ul><li><p><strong>Best for</strong>: End-to-end document Q&amp;A systems, complex data processing workflows</p></li><li><p><strong>Core Capabilities</strong>:</p><ul><li>Built-in preprocessing (OCR, PDF parsing), multimodal retrieval, post-processing</li><li>Visual pipeline designer (low-code)</li></ul></li><li><p><strong>Advantages</strong>:</p><ul><li>Supports <strong>hybrid retrieval</strong> (keyword + vector + semantic), higher accuracy</li><li>Provides REST API for rapid deployment</li></ul></li><li><p><strong>Architecture Diagram</strong>:</p><div class="language-mermaid vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">mermaid</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">graph LR</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    A[Document] --&gt; B[Preprocessing]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    B --&gt; C[Vectorization]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    C --&gt; D[Storage]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    D --&gt; E[Retrieval]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    E --&gt; F[Generation]</span></span></code></pre></div><p><strong>Official Site</strong>: Haystack</p></li></ul><hr><h3 id="_3-microsoft-semantic-kernel-microsoft-ecosystem-integration" tabindex="-1"><strong>3. Microsoft Semantic Kernel (Microsoft Ecosystem Integration)</strong> <a class="header-anchor" href="#_3-microsoft-semantic-kernel-microsoft-ecosystem-integration" aria-label="Permalink to &quot;**3. Microsoft Semantic Kernel (Microsoft Ecosystem Integration)**&quot;">​</a></h3><ul><li><strong>Best for</strong>: Azure cloud users, integration with Office 365/SharePoint data</li><li><strong>Core Capabilities</strong>: <ul><li>Native support for Azure AI Search (formerly Cognitive Search) as retrieval backend</li><li>Built-in <strong>Planner</strong> module for dynamic RAG workflow planning</li></ul></li><li><strong>Advantages</strong>: <ul><li>Directly reads files from Teams/Outlook/OneDrive</li><li>Integrates with Power Platform low-code tools</li></ul></li><li><strong>Official Site</strong>: Semantic Kernel</li></ul><hr><h3 id="_4-vectara-out-of-the-box-rag-api" tabindex="-1"><strong>4. Vectara (Out-of-the-Box RAG API)</strong> <a class="header-anchor" href="#_4-vectara-out-of-the-box-rag-api" aria-label="Permalink to &quot;**4. Vectara (Out-of-the-Box RAG API)**&quot;">​</a></h3><ul><li><strong>Best for</strong>: No need to manage vector DB or retrieval optimization, fast launch</li><li><strong>Core Capabilities</strong>: <ul><li>Fully managed retrieval service; upload documents and get Q&amp;A API</li><li>Automatic chunking, vectorization, query expansion</li></ul></li><li><strong>Advantages</strong>: <ul><li>Generous free tier (1,000 pages/month)</li><li>Supports <strong>factuality scoring</strong> (checks consistency between generation and retrieved content)</li></ul></li><li><strong>Official Site</strong>: Vectara</li></ul><hr><h3 id="_5-relevance-ai-visual-rag-workflow" tabindex="-1"><strong>5. Relevance AI (Visual RAG Workflow)</strong> <a class="header-anchor" href="#_5-relevance-ai-visual-rag-workflow" aria-label="Permalink to &quot;**5. Relevance AI (Visual RAG Workflow)**&quot;">​</a></h3><ul><li><strong>Best for</strong>: Non-technical teams to quickly build RAG applications</li><li><strong>Core Capabilities</strong>: <ul><li>Drag-and-drop design of retrieval-generation workflows</li><li>Built-in A/B testing and analytics dashboards</li></ul></li><li><strong>Advantages</strong>: <ul><li>Supports multimodal (joint text + image retrieval)</li><li>One-click deployment as a ChatGPT plugin</li></ul></li><li><strong>Official Site</strong>: Relevance AI</li></ul><hr><h3 id="selection-advice" tabindex="-1"><strong>Selection Advice</strong>: <a class="header-anchor" href="#selection-advice" aria-label="Permalink to &quot;**Selection Advice**:&quot;">​</a></h3><table tabindex="0"><thead><tr><th style="text-align:center;">Tool</th><th style="text-align:center;">Suitable For</th><th style="text-align:center;">Learning Curve</th><th style="text-align:center;">Customization</th></tr></thead><tbody><tr><td style="text-align:center;"><strong>Dify</strong></td><td style="text-align:center;">Full-Stack Devs</td><td style="text-align:center;">Low</td><td style="text-align:center;">Medium</td></tr><tr><td style="text-align:center;"><strong>LangChain+Llama</strong></td><td style="text-align:center;">AI Engineers</td><td style="text-align:center;">High</td><td style="text-align:center;">High</td></tr><tr><td style="text-align:center;"><strong>Haystack</strong></td><td style="text-align:center;">Enterprise Teams</td><td style="text-align:center;">Medium</td><td style="text-align:center;">High</td></tr><tr><td style="text-align:center;"><strong>Vectara</strong></td><td style="text-align:center;">PMs/Entrepreneurs</td><td style="text-align:center;">Very Low</td><td style="text-align:center;">Low</td></tr><tr><td style="text-align:center;"><strong>Relevance AI</strong></td><td style="text-align:center;">Non-Technical</td><td style="text-align:center;">Very Low</td><td style="text-align:center;">Medium</td></tr></tbody></table><p>If you want to quickly validate RAG effectiveness, start with <strong>Dify</strong> or <strong>Vectara</strong>; for deep customization, choose <strong>LangChain</strong> or <strong>Haystack</strong>.</p>`,50)]))}const c=s(n,[["render",l]]);export{k as __pageData,c as default};
