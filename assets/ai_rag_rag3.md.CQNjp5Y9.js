import{_ as t,c as n,o as e,ae as s}from"./chunks/framework.BjlC_BXf.js";const h=JSON.parse('{"title":"以下是目前主流的 RAG 应用开发平台 推荐，根据不同的技术需求和场景，可以选择更适合的工具：","description":"","frontmatter":{},"headers":[],"relativePath":"ai/rag/rag3.md","filePath":"ai/rag/rag3.md"}'),l={name:"ai/rag/rag3.md"};function i(r,a,o,p,g,c){return e(),n("div",null,a[0]||(a[0]=[s(`<h2 id="已有多个开源工具和平台可以快速搭建支持多模态文档的-rag-问答系统-无需从零开发" tabindex="-1">已有多个开源工具和平台可以快速搭建支持多模态文档的 RAG 问答系统，无需从零开发 <a class="header-anchor" href="#已有多个开源工具和平台可以快速搭建支持多模态文档的-rag-问答系统-无需从零开发" aria-label="Permalink to &quot;已有多个开源工具和平台可以快速搭建支持多模态文档的 RAG 问答系统，无需从零开发&quot;">​</a></h2><h3 id="_1-使用现成框架-适合开发者" tabindex="-1"><strong>1. 使用现成框架（适合开发者）</strong> <a class="header-anchor" href="#_1-使用现成框架-适合开发者" aria-label="Permalink to &quot;**1. 使用现成框架（适合开发者）**&quot;">​</a></h3><h4 id="_1-langchain-llamaindex-openai" tabindex="-1"><strong>(1) LangChain + LlamaIndex + OpenAI</strong> <a class="header-anchor" href="#_1-langchain-llamaindex-openai" aria-label="Permalink to &quot;**(1) LangChain + LlamaIndex + OpenAI**&quot;">​</a></h4><ul><li><p><strong>特点</strong>：代码灵活，支持自定义流程，适合复杂场景。</p></li><li><p><strong>代码示例</strong>：</p><p>python</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>from langchain.document_loaders import DirectoryLoader</span></span>
<span class="line"><span>from llama_index import VectorStoreIndex, ServiceContext</span></span>
<span class="line"><span></span></span>
<span class="line"><span># 加载多格式文档（自动识别PDF/Excel/图片等）</span></span>
<span class="line"><span>loader = DirectoryLoader(&quot;./docs&quot;, glob=&quot;**/*&quot;)</span></span>
<span class="line"><span>documents = loader.load()</span></span>
<span class="line"><span></span></span>
<span class="line"><span># 构建向量索引（自动分块+嵌入）</span></span>
<span class="line"><span>index = VectorStoreIndex.from_documents(documents)</span></span>
<span class="line"><span></span></span>
<span class="line"><span># 问答查询</span></span>
<span class="line"><span>query_engine = index.as_query_engine()</span></span>
<span class="line"><span>response = query_engine.query(&quot;图片中的产品价格是多少？&quot;)</span></span>
<span class="line"><span>print(response.response)</span></span></code></pre></div></li></ul><h4 id="_2-hugging-face-transformers-pipeline" tabindex="-1"><strong>(2) Hugging Face Transformers Pipeline</strong> <a class="header-anchor" href="#_2-hugging-face-transformers-pipeline" aria-label="Permalink to &quot;**(2) Hugging Face Transformers Pipeline**&quot;">​</a></h4><ul><li><p><strong>特点</strong>：免费开源，支持本地运行。</p><p>python</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>from transformers import pipeline</span></span>
<span class="line"><span>from PIL import Image</span></span>
<span class="line"><span></span></span>
<span class="line"><span># 多模态问答（文本+图片）</span></span>
<span class="line"><span>vqa_pipeline = pipeline(&quot;visual-question-answering&quot;, model=&quot;dandelin/vilt-b32-finetuned-vqa&quot;)</span></span>
<span class="line"><span>answer = vqa_pipeline(Image.open(&quot;product.jpg&quot;), &quot;图中是什么产品？&quot;)</span></span>
<span class="line"><span>print(answer)</span></span></code></pre></div></li></ul><hr><h3 id="_2-使用一站式工具-低代码-无代码" tabindex="-1"><strong>2. 使用一站式工具（低代码/无代码）</strong> <a class="header-anchor" href="#_2-使用一站式工具-低代码-无代码" aria-label="Permalink to &quot;**2. 使用一站式工具（低代码/无代码）**&quot;">​</a></h3><h4 id="_1-privategpt" tabindex="-1"><strong>(1) PrivateGPT</strong> <a class="header-anchor" href="#_1-privategpt" aria-label="Permalink to &quot;**(1) PrivateGPT**&quot;">​</a></h4><ul><li><p><strong>GitHub</strong>: <a href="https://github.com/imartinez/privateGPT" target="_blank" rel="noreferrer">https://github.com/imartinez/privateGPT</a></p></li><li><p><strong>特点</strong>：</p><ul><li>支持 PDF、Word、Excel、PPT、图片（需OCR）</li><li>本地运行，数据不泄露</li><li>命令行交互或API</li></ul></li><li><p><strong>使用步骤</strong>：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span># 安装</span></span>
<span class="line"><span>git clone https://github.com/imartinez/privateGPT</span></span>
<span class="line"><span>cd privateGPT &amp;&amp; pip install -r requirements.txt</span></span>
<span class="line"><span></span></span>
<span class="line"><span># 将文档放入source_documents目录，运行</span></span>
<span class="line"><span>python ingest.py  # 构建索引</span></span>
<span class="line"><span>python privateGPT.py  # 启动问答</span></span></code></pre></div></li></ul><h4 id="_2-flowise" tabindex="-1"><strong>(2) Flowise</strong> <a class="header-anchor" href="#_2-flowise" aria-label="Permalink to &quot;**(2) Flowise**&quot;">​</a></h4><ul><li><strong>官网</strong>: <a href="https://flowiseai.com/" target="_blank" rel="noreferrer">https://flowiseai.com</a></li><li><strong>特点</strong>： <ul><li>可视化拖拽搭建 RAG 流程</li><li>支持 PDF/Excel/文本，可扩展图片处理</li></ul></li><li><strong>用法</strong>： <ol><li>通过界面上传文档</li><li>连接向量数据库（如 Pinecone）</li><li>配置 LLM（如 GPT-4）生成答案</li></ol></li></ul><hr><h3 id="_3-云服务平台-快速部署-需付费" tabindex="-1"><strong>3. 云服务平台（快速部署，需付费）</strong> <a class="header-anchor" href="#_3-云服务平台-快速部署-需付费" aria-label="Permalink to &quot;**3. 云服务平台（快速部署，需付费）**&quot;">​</a></h3><h4 id="_1-google-vertex-ai" tabindex="-1"><strong>(1) Google Vertex AI</strong> <a class="header-anchor" href="#_1-google-vertex-ai" aria-label="Permalink to &quot;**(1) Google Vertex AI**&quot;">​</a></h4><ul><li><strong>功能</strong>： <ul><li>内置文档解析（PDF/Excel/CSV）</li><li>自动生成问答系统</li></ul></li><li><strong>步骤</strong>： <ol><li>在 Google Cloud 控制台上传文档</li><li>使用 <code>Vertex AI Search</code> 创建知识库</li><li>通过 API 查询答案</li></ol></li></ul><h4 id="_2-azure-ai-document-intelligence" tabindex="-1"><strong>(2) Azure AI Document Intelligence</strong> <a class="header-anchor" href="#_2-azure-ai-document-intelligence" aria-label="Permalink to &quot;**(2) Azure AI Document Intelligence**&quot;">​</a></h4><ul><li><strong>功能</strong>： <ul><li>支持扫描件PDF、图片、表格的 OCR</li><li>与 Azure OpenAI 集成实现 RAG</li></ul></li><li><strong>文档</strong>: <a href="https://learn.microsoft.com/azure/ai-services/document-intelligence/tutorial-rag" target="_blank" rel="noreferrer">Azure 多模态 RAG 教程</a></li></ul><hr><h3 id="_4-开源项目快速集成" tabindex="-1"><strong>4. 开源项目快速集成</strong> <a class="header-anchor" href="#_4-开源项目快速集成" aria-label="Permalink to &quot;**4. 开源项目快速集成**&quot;">​</a></h3><h4 id="_1-milvus-towhee" tabindex="-1"><strong>(1) Milvus + Towhee</strong> <a class="header-anchor" href="#_1-milvus-towhee" aria-label="Permalink to &quot;**(1) Milvus + Towhee**&quot;">​</a></h4><ul><li><p><strong>场景</strong>：处理海量多模态数据</p></li><li><p><strong>代码</strong>：</p><p>python</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>from towhee import pipe, ops</span></span>
<span class="line"><span>from milvus import default_server</span></span>
<span class="line"><span></span></span>
<span class="line"><span># 启动 Milvus 向量库</span></span>
<span class="line"><span>default_server.start()</span></span>
<span class="line"><span></span></span>
<span class="line"><span># 构建多模态处理管道</span></span>
<span class="line"><span>p = (</span></span>
<span class="line"><span>    pipe.input(&quot;file_path&quot;)</span></span>
<span class="line"><span>    .map(&quot;file_path&quot;, &quot;text&quot;, ops.text_extractor())</span></span>
<span class="line"><span>    .map(&quot;text&quot;, &quot;vec&quot;, ops.text_embedding.sbert())</span></span>
<span class="line"><span>    .output(&quot;text&quot;, &quot;vec&quot;)</span></span>
<span class="line"><span>)</span></span>
<span class="line"><span></span></span>
<span class="line"><span># 查询</span></span>
<span class="line"><span>results = p(&quot;report.pdf&quot;).get()</span></span></code></pre></div></li></ul><h4 id="_2-unstructured-io" tabindex="-1"><strong>(2) Unstructured.io</strong> <a class="header-anchor" href="#_2-unstructured-io" aria-label="Permalink to &quot;**(2) Unstructured.io**&quot;">​</a></h4><ul><li><p><strong>文档解析工具</strong>：统一处理 PDF/Excel/图片等</p><p>python</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>from unstructured.partition.auto import partition</span></span>
<span class="line"><span></span></span>
<span class="line"><span>elements = partition(&quot;document.jpg&quot;)</span></span>
<span class="line"><span>text = &quot;\\n&quot;.join([e.text for e in elements])</span></span></code></pre></div></li></ul><hr><h3 id="选择建议" tabindex="-1"><strong>选择建议</strong> <a class="header-anchor" href="#选择建议" aria-label="Permalink to &quot;**选择建议**&quot;">​</a></h3><table tabindex="0"><thead><tr><th style="text-align:left;">需求场景</th><th style="text-align:left;">推荐工具</th><th style="text-align:left;">优点</th><th style="text-align:left;">缺点</th></tr></thead><tbody><tr><td style="text-align:left;">快速本地部署</td><td style="text-align:left;">PrivateGPT</td><td style="text-align:left;">一键运行，隐私安全</td><td style="text-align:left;">对图片支持较弱</td></tr><tr><td style="text-align:left;">企业级云服务</td><td style="text-align:left;">Google Vertex AI</td><td style="text-align:left;">全托管，支持大规模数据</td><td style="text-align:left;">费用较高</td></tr><tr><td style="text-align:left;">可视化搭建</td><td style="text-align:left;">Flowise</td><td style="text-align:left;">无需代码，灵活扩展</td><td style="text-align:left;">需自行配置多模态模块</td></tr><tr><td style="text-align:left;">开源可控</td><td style="text-align:left;">LangChain + LlamaIndex</td><td style="text-align:left;">完全自定义</td><td style="text-align:left;">开发成本高</td></tr></tbody></table><hr><h3 id="关键提示" tabindex="-1"><strong>关键提示</strong> <a class="header-anchor" href="#关键提示" aria-label="Permalink to &quot;**关键提示**&quot;">​</a></h3><ol><li><strong>图片处理</strong>：若需理解图像语义（非OCR文字），需使用多模态模型如： <ul><li>CLIP（开源）：生成图像向量</li><li>GPT-4 Vision（API）：直接理解图片内容</li></ul></li><li><strong>文档安全</strong>：敏感数据建议使用 PrivateGPT 或本地部署的 Milvus</li><li><strong>成本控制</strong>：云服务按调用次数计费，预估用量后选择套餐</li></ol><h1 id="以下是目前主流的-rag-应用开发平台-推荐-根据不同的技术需求和场景-可以选择更适合的工具" tabindex="-1">以下是目前主流的 <strong>RAG 应用开发平台</strong> 推荐，根据不同的技术需求和场景，可以选择更适合的工具： <a class="header-anchor" href="#以下是目前主流的-rag-应用开发平台-推荐-根据不同的技术需求和场景-可以选择更适合的工具" aria-label="Permalink to &quot;以下是目前主流的 **RAG 应用开发平台** 推荐，根据不同的技术需求和场景，可以选择更适合的工具：&quot;">​</a></h1><hr><h3 id="_1-langchain-llamaindex-代码优先-灵活性强" tabindex="-1"><strong>1. LangChain + LlamaIndex（代码优先，灵活性强）</strong> <a class="header-anchor" href="#_1-langchain-llamaindex-代码优先-灵活性强" aria-label="Permalink to &quot;**1. LangChain + LlamaIndex（代码优先，灵活性强）**&quot;">​</a></h3><ul><li><p><strong>适用场景</strong>：需要高度定制化 RAG 流程（如复杂检索策略、多数据源接入）</p></li><li><p><strong>核心能力</strong>：</p><ul><li><strong>LangChain</strong>：提供 RAG 流程编排（检索+生成链式调用）</li><li><strong>LlamaIndex</strong>：专注于文档索引和高效检索优化</li></ul></li><li><p><strong>优势</strong>：</p><ul><li>支持 Python/JS 开发，无缝集成主流向量数据库（Milvus、Pinecone、Weaviate）</li><li>可自由替换大模型（OpenAI、Anthropic、本地模型等）</li></ul></li><li><p><strong>示例代码</strong>：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>from llama_index import VectorStoreIndex, SimpleDirectoryReader</span></span>
<span class="line"><span>from langchain.chat_models import ChatOpenAI</span></span>
<span class="line"><span></span></span>
<span class="line"><span>documents = SimpleDirectoryReader(&quot;data&quot;).load_data()</span></span>
<span class="line"><span>index = VectorStoreIndex.from_documents(documents)</span></span>
<span class="line"><span>query_engine = index.as_query_engine(llm=ChatOpenAI())</span></span>
<span class="line"><span>print(query_engine.query(&quot;RAG 的核心步骤是什么？&quot;))</span></span></code></pre></div></li><li><p><strong>官网</strong>：</p><ul><li>LangChain</li><li>LlamaIndex</li></ul></li></ul><hr><h3 id="_2-haystack-企业级-rag-解决方案" tabindex="-1"><strong>2. Haystack（企业级 RAG 解决方案）</strong> <a class="header-anchor" href="#_2-haystack-企业级-rag-解决方案" aria-label="Permalink to &quot;**2. Haystack（企业级 RAG 解决方案）**&quot;">​</a></h3><ul><li><p><strong>适用场景</strong>：需要端到端的文档问答系统，支持复杂数据处理流程</p></li><li><p><strong>核心能力</strong>：</p><ul><li>内置预处理（OCR、PDF 解析）、多模态检索、结果后处理</li><li>可视化 Pipeline 设计器（低代码）</li></ul></li><li><p><strong>优势</strong>：</p><ul><li>支持 <strong>混合检索</strong>（关键词+向量+语义），精度更高</li><li>提供 REST API 快速部署</li></ul></li><li><p><strong>架构图</strong>：</p><div class="language-mermaid vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">mermaid</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">graph LR</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    A[文档] --&gt; B[预处理]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    B --&gt; C[向量化]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    C --&gt; D[存储]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    D --&gt; E[检索]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    E --&gt; F[生成]</span></span></code></pre></div><p><strong>官网</strong>： Haystack</p></li></ul><hr><h3 id="_3-microsoft-semantic-kernel-微软生态集成" tabindex="-1"><strong>3. Microsoft Semantic Kernel（微软生态集成）</strong> <a class="header-anchor" href="#_3-microsoft-semantic-kernel-微软生态集成" aria-label="Permalink to &quot;**3. Microsoft Semantic Kernel（微软生态集成）**&quot;">​</a></h3><ul><li><strong>适用场景</strong>：Azure 云服务用户，或需要与 Office 365、SharePoint 数据打通</li><li><strong>核心能力</strong>： <ul><li>原生支持 Azure AI Search（原 Cognitive Search）作为检索后端</li><li>内置 <strong>Planner</strong> 模块，可动态规划 RAG 流程</li></ul></li><li><strong>优势</strong>： <ul><li>直接读取 Teams/Outlook/OneDrive 中的文件</li><li>与 Power Platform 低代码工具集成</li></ul></li><li><strong>官网</strong>： Semantic Kernel</li></ul><hr><h3 id="_4-vectara-开箱即用的-rag-api" tabindex="-1"><strong>4. Vectara（开箱即用的 RAG API）</strong> <a class="header-anchor" href="#_4-vectara-开箱即用的-rag-api" aria-label="Permalink to &quot;**4. Vectara（开箱即用的 RAG API）**&quot;">​</a></h3><ul><li><strong>适用场景</strong>：不想处理向量数据库和检索优化，快速上线</li><li><strong>核心能力</strong>： <ul><li>完全托管的检索服务，上传文档即可获得问答 API</li><li>自动处理分块、向量化、查询扩展</li></ul></li><li><strong>优势</strong>： <ul><li>免费额度充足（每月 1000 页文档）</li><li>支持 <strong>事实性评分</strong>（检测生成结果与检索内容的一致性）</li></ul></li><li><strong>官网</strong>： Vectara</li></ul><hr><h3 id="_5-relevance-ai-可视化-rag-工作流" tabindex="-1"><strong>5. Relevance AI（可视化 RAG 工作流）</strong> <a class="header-anchor" href="#_5-relevance-ai-可视化-rag-工作流" aria-label="Permalink to &quot;**5. Relevance AI（可视化 RAG 工作流）**&quot;">​</a></h3><ul><li><strong>适用场景</strong>：非技术团队快速搭建 RAG 应用</li><li><strong>核心能力</strong>： <ul><li>拖拽式设计检索-生成流程</li><li>内置 A/B 测试和效果分析面板</li></ul></li><li><strong>优势</strong>： <ul><li>支持多模态（文本+图像联合检索）</li><li>一键部署为 ChatGPT 插件</li></ul></li><li><strong>官网</strong>： Relevance AI</li></ul><hr><h3 id="选型建议" tabindex="-1"><strong>选型建议</strong>： <a class="header-anchor" href="#选型建议" aria-label="Permalink to &quot;**选型建议**：&quot;">​</a></h3><table tabindex="0"><thead><tr><th style="text-align:center;">工具</th><th style="text-align:center;">适合人群</th><th style="text-align:center;">学习成本</th><th style="text-align:center;">定制化能力</th></tr></thead><tbody><tr><td style="text-align:center;"><strong>Dify</strong></td><td style="text-align:center;">全栈开发者</td><td style="text-align:center;">低</td><td style="text-align:center;">中</td></tr><tr><td style="text-align:center;"><strong>LangChain+Llama</strong></td><td style="text-align:center;">AI 工程师</td><td style="text-align:center;">高</td><td style="text-align:center;">高</td></tr><tr><td style="text-align:center;"><strong>Haystack</strong></td><td style="text-align:center;">企业开发团队</td><td style="text-align:center;">中</td><td style="text-align:center;">高</td></tr><tr><td style="text-align:center;"><strong>Vectara</strong></td><td style="text-align:center;">产品经理/创业者</td><td style="text-align:center;">极低</td><td style="text-align:center;">低</td></tr><tr><td style="text-align:center;"><strong>Relevance AI</strong></td><td style="text-align:center;">非技术背景</td><td style="text-align:center;">极低</td><td style="text-align:center;">中</td></tr></tbody></table><p>如果需要快速验证 RAG 效果，推荐从 <strong>Dify/Vectara</strong> 开始；如需深度定制，选择 <strong>LangChain/Haystack</strong>。</p>`,50)]))}const u=t(l,[["render",i]]);export{h as __pageData,u as default};
