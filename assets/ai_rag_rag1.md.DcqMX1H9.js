import{_ as e,c as a,o as l,ae as r}from"./chunks/framework.BjlC_BXf.js";const g=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"ai/rag/rag1.md","filePath":"ai/rag/rag1.md"}'),i={name:"ai/rag/rag1.md"};function n(o,t,s,p,d,h){return l(),a("div",null,t[0]||(t[0]=[r('<h3 id="一、rag" tabindex="-1">一、RAG <a class="header-anchor" href="#一、rag" aria-label="Permalink to &quot;一、RAG&quot;">​</a></h3><h5 id="_1、是什么" tabindex="-1">1、是什么 <a class="header-anchor" href="#_1、是什么" aria-label="Permalink to &quot;1、是什么&quot;">​</a></h5><p>检索增强生成（RAG）是一种将****动态信息检索*<em><strong>与</strong></em>*静态知识生成****相结合的架构。它通过实时从结构化知识库中提取相关片段，为大语言模型提供上下文锚点。</p><p>RAG 可以用您选择的外部知识源（例如数据存储库、文本集合和既有文档）来补充大语言模型中的数据。这种方法会先把这些资源切分成较小的片段，再在向量数据库中为其添加索引，然后将其用作参考资料以提供更准确的回答。</p><p>RAG 的实用之处在于它指示大语言模型从您选择的一个或多个事实来源中检索特定的实时信息。RAG 可通过提供定制体验来节省成本，不会产生模型训练和微调费用。它还可以在查询大语言模型时仅发送最相关的信息（而非整篇冗长的文档），从而节省资源。</p><h5 id="_2、原理" tabindex="-1">2、原理 <a class="header-anchor" href="#_2、原理" aria-label="Permalink to &quot;2、原理&quot;">​</a></h5><p>RAG 架构的工作原理是从外部来源检索数据，将其处理到大语言模型的语境中，然后基于组合来源生成回答。该过程包括三个主要阶段：数据准备、检索和生成。</p><p><strong>第 1 步：数据准备（用于检索）</strong></p><ul><li><p>**源文档和加载文档：**识别并获取要与大语言模型共享的源文档，并确保这些文档采用大语言模型能够理解的格式，通常是文本文件、数据库表或 PDF 格式。无论源格式如何，在嵌入向量数据库之前，每份文档都需要转换为文本文件。该过程也称为 ETL 阶段：提取（Extract）、转换（Transform）和加载（Load）。ETL 可确保对原始数据进行清理和整理，使数据为存储、分析和机器学习做好准备。</p></li><li><p>**转换：**进行“文本分割”或“分块”，使文档为检索做好准备。这意味着对更新后的文档进行解析，然后根据不同的特征以目录的形式将其编入相关的“块”。例如，按段落编排的文档可能比按表格和图表编排的文档更易于模型搜索和检索。</p><p>分块可以基于语义、句子、标记、格式、HTML 字符或代码类型等因素。许多开源框架都可以协助进行文档注入，其中包括 <a href="https://www.llamaindex.ai/open-source" target="_blank" rel="noreferrer">LlamaIndex</a> 和 <a href="https://www.langchain.com/" target="_blank" rel="noreferrer">LangChain</a>。</p></li><li><p>**嵌入：**嵌入使用专门的机器学习模型（向量嵌入模型）将数据转换为数值向量，使您能够应用数学运算来评估数据之间的相似性和差异性。借助嵌入功能，您可以将文本（或图像）转换为向量，从而捕获内容的核心含义，同时丢弃不相关的细节。嵌入过程可为数据块分配一个数值（例如 [1.2，-0.9，0.3]），并在向量数据库这种更大的系统中为其添加索引。</p><p>在向量数据库中，此数值帮助 RAG 架构指示内容块之间的关联，并对数据进行整理以优化检索。这种索引方式旨在对向量进行结构化处理，从而将相似的概念存储在相邻的坐标中。例如，“咖啡”和“茶”的位置会离得很近。“热饮”也会离它们很近。“手机”、“电视”等不相关概念的位置则会离它们很远。两个向量点之间的距离或接近程度有助于模型确定对哪些信息进行检索并使其包含在用户查询的输出中。</p></li><li><p>**存储：**来自多个来源（您选择的外部文档及大语言模型）的组合数据会被存储在中央存储库中。</p></li></ul><p><strong>第 2 步：检索</strong></p><ul><li><p>将数据编入向量数据库后，算法便会搜索并检索与用户提示词和查询相关的信息片段。LangChain 等框架支持许多不同的检索算法，其中包括基于语义、元数据和父文档等数据相似性的检索。</p><p>在开放域使用者设置中，信息检索来自互联网上已添加索引的文档，通过信息源的 API 对这些文档进行访问。在封闭域的企业设置中，信息需要保持私密性且不受外部来源的影响，通过 RAG 架构进行检索可以保持本地状态并提高安全性。</p><p>最后，将检索到的数据注入提示符中并发送给大语言模型进行处理。</p></li></ul><p><strong>第 3 步：生成</strong></p><ul><li>**输出：**将响应呈现给用户。如果 RAG 方法按预期发挥作用，用户就会获得基于所提供的源知识的准确回答。</li></ul><h5 id="_3、怎么实现" tabindex="-1">3、怎么实现 <a class="header-anchor" href="#_3、怎么实现" aria-label="Permalink to &quot;3、怎么实现&quot;">​</a></h5><ol><li>知识库建设阶段</li></ol><ul><li>数据源评估：覆盖率/质量/更新频率</li><li>元数据设计：来源/时效/权威性标签</li><li>版本管理：增量更新与回溯机制</li></ul><ol start="2"><li>系统集成阶段</li></ol><ul><li>检索策略配置： <ul><li>单次检索 vs 多轮精炼</li><li>精确匹配 vs 语义泛化</li></ul></li><li>生成参数调优： <ul><li>引用格式规范化</li><li>术语一致性保持</li></ul></li></ul><ol start="3"><li>持续优化阶段</li></ol><ul><li>质量监控指标： <ul><li>检索命中率</li><li>生成事实准确率</li><li>用户满意度</li></ul></li><li>反馈闭环设计： <ul><li>错误案例标注</li><li>自动触发再训练</li></ul></li></ul><h5 id="_4、优势" tabindex="-1">4、优势 <a class="header-anchor" href="#_4、优势" aria-label="Permalink to &quot;4、优势&quot;">​</a></h5><p>RAG 架构由于有内置检索机制，因而能够利用大语言模型常规训练之外的额外数据源。通过 RAG 将大语言模型建立在外部的一系列可验证的事实上，可实现以下几个有益目标：</p><p><strong>准确性</strong> RAG 为大语言模型提供了引用来源，因此，用户可以加以验证。您还可以将 RAG 架构设计为在问题超出其知识范围时将“我不知道”作为回答。总体而言，RAG 可以减少大语言模型在输出结果中分享错误或误导性信息的几率，进而可能会提高用户的信任度。</p><p><strong>成本效益</strong> 对大语言模型进行重新训练和微调既昂贵又耗时，就像从头开始创建一个<a href="https://www.redhat.com/zh/topics/ai/what-are-foundation-models" target="_blank" rel="noreferrer">基础模型</a>（例如构建一个聊天机器人）并添加特定领域的信息一样。借助 RAG，用户可以将新数据引入大语言模型，还可以通过上传文档或文件来轻松替换或更新信息源。</p><p>RAG 还可以降低推理成本。大语言模型查询的成本很高，如果您在本地运行模型，您自己的硬件需要能够满足需求，如果您通过应用编程接口（API）使用外部服务，则会产生计费账单。RAG 可以只发送参考资料中最相关的部分，而非一次将整个参考文档发给 LLM，因此，可减小查询规模并提高效率。</p><p><strong>开发人员控制</strong> 与传统的微调方法相比，RAG 提供了一种更方便、更直接的方式来获取反馈、进行故障排除以及修复应用。对开发人员而言，RAG 架构的最大优势在于他们可以利用特定域的最新信息流。</p><p><strong>数据主权和隐私</strong> 之前，使用机密信息对大语言模型工具进行微调一直有风险，因为大语言模型可能会泄露训练数据中的信息。而 RAG 允许将敏感数据保留在本地，同时继续将其用于向本地或值得信赖的外部大语言模型提供信息，为这类隐私问题提供了解决方案。RAG 架构还可以设置为将敏感信息检索限制在不同的授权级别上，即，某些用户可以基于其安全许可级别访问特定信息。</p><h5 id="_5、应用场景" tabindex="-1">5、应用场景 <a class="header-anchor" href="#_5、应用场景" aria-label="Permalink to &quot;5、应用场景&quot;">​</a></h5><table tabindex="0"><thead><tr><th style="text-align:center;">场景类型</th><th style="text-align:center;">核心需求</th><th style="text-align:center;">技术适配要点</th></tr></thead><tbody><tr><td style="text-align:center;">企业知识库</td><td style="text-align:center;">多数据源融合</td><td style="text-align:center;">权限分级控制</td></tr><tr><td style="text-align:center;">智能客服</td><td style="text-align:center;">实时准确性</td><td style="text-align:center;">对话状态管理</td></tr><tr><td style="text-align:center;">学术研究</td><td style="text-align:center;">文献溯源能力</td><td style="text-align:center;">专业术语处理</td></tr><tr><td style="text-align:center;">合规审查</td><td style="text-align:center;">条款精确匹配</td><td style="text-align:center;">法律效力判断</td></tr></tbody></table><p>RAG 架构具有许多潜在用例。以下是最流行的几种用途：</p><ul><li>**客户服务：**对聊天机器人进行编程，让其通过对特定文档的深入了解来回答客户的咨询，从而缩短问题解决时间，使客户支持系统更高效。</li><li>**生成洞察：**RAG 可以帮助您从已有文档中查询。通过 RAG 架构将大语言模型与年度报告、营销文档、社交媒体评论、客户评价、调查结果、研究文档或其他材料联系起来，查找有助于您更好地了解资源的回答。请注意，您可以通过 RAG 直接连接到实时数据源（例如社交媒体动态、网站或其他经常更新的来源），以便生成实时且实用的回答。</li><li>**医疗信息系统：**RAG 架构可改善提供医疗信息或建议的系统。RAG 支持查看个人病史等因素、预约挂号以及查看最新医学研究和指南，帮助患者获得所需的支持和服务。</li></ul><h5 id="_6、解决方案" tabindex="-1">6、<strong>解决方案</strong> <a class="header-anchor" href="#_6、解决方案" aria-label="Permalink to &quot;6、**解决方案**&quot;">​</a></h5><p>1）创建RAG应用</p><p>2）构建文档处理管道</p><p>3）浏览大语言模型目录</p><p>4）选择合适的模型</p><h5 id="_7、概念理解" tabindex="-1">7、概念理解 <a class="header-anchor" href="#_7、概念理解" aria-label="Permalink to &quot;7、概念理解&quot;">​</a></h5><p>1）向量数据库</p><p>向量数据库（Vector Database）是一种专门用于存储、检索和管理向量嵌入（Vector Embeddings）的数据库系统。它在与大语言模型（LLM）结合的应用中扮演核心角色</p><p>传统数据库难以高效处理高维向量相似度搜索，而向量数据库（如Milvus、Pinecone、Weaviate）针对此类操作优化，支持大规模数据。</p>',40)]))}const u=e(i,[["render",n]]);export{g as __pageData,u as default};
